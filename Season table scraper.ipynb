{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f8ee7e4",
   "metadata": {},
   "source": [
    "# Season table scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce9f758",
   "metadata": {},
   "source": [
    "### To get our data we will get it from fbref.com "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a822935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'[season_table_screenshot.png]' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "![season_table_screenshot.png](season_table_screenshot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8824018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "# Web scraping liberaries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Data analysis liberaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b59c2b",
   "metadata": {},
   "source": [
    "### Understanding the structure and code of the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc0b5cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_to_list(content_list):\n",
    "    '''\n",
    "    Input : Content of tags \n",
    "    Output : Return a list without space and tags as element of list.\n",
    "    \n",
    "    '''\n",
    "    list_ = []\n",
    "    for i in range(len(content_list)):\n",
    "        if content_list[i] == \" \" or content_list[i] == \"\\n\":\n",
    "            pass\n",
    "        else:\n",
    "            list_.append(content_list[i])\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6be6909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_extract_from_contents(contents_list):\n",
    "    '''\n",
    "    Input : \n",
    "    Output :  \n",
    "    \n",
    "    '''\n",
    "    list_ = []\n",
    "    for i in range(len(contents_list)):\n",
    "        if contents_list[i] == \" \" or contents_list[i] == \"\\n\":\n",
    "            pass\n",
    "        else:\n",
    "            list_.append(contents_list[i].text)\n",
    "    \n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8547cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary(list_):\n",
    "    '''\n",
    "    Input : List of elements as keys \n",
    "    Output : Return a dictionary with \n",
    "    '''\n",
    "    dictionary = {}\n",
    "    for i in list_:\n",
    "        dictionary[i] = []\n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb5b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_table(table_headers_list,table_content):\n",
    "    dictionary = create_dictionary(table_headers_list)\n",
    "    \n",
    "    for i in range(len(table_content)):\n",
    "        detail = text_extract_from_contents(table_content[i].contents)\n",
    "        for j in range(len(table_headers_list)):\n",
    "            dictionary[table_headers_list[j]].append(detail[j])\n",
    "        \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4957e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_to_soup(url):\n",
    "    # Requesting web server to get acces to the web page and converting it into text\n",
    "    page = requests.get(url)\n",
    "\n",
    "    # Checking status code for URL\n",
    "    code = page.status_code\n",
    "    print(code)\n",
    "    \n",
    "    # Instantiating BeautifulSoup library\n",
    "    soup = BeautifulSoup(page.text)\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ce87e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(soup_):\n",
    "    # Getting tags for regular season tabel\n",
    "    table_tags = soup_.find('table')\n",
    "    \n",
    "    # Table header section    \n",
    "    # Separating tags for scraping the text\n",
    "    content_to_list(table_tags.thead.tr.contents)\n",
    "\n",
    "    # Scraping the text from tags contents\n",
    "    table_header_list = text_extract_from_contents(table_tags.thead.tr.contents)\n",
    "    \n",
    "    # Table body section \n",
    "    # Scraping the body tags from table    \n",
    "    table_details = content_to_list(table_tags.tbody.contents)\n",
    "    \n",
    "    # Creating a final table in the as dictionary\n",
    "    table = final_table(headers_list=table_header_list,table_content=table_details)\n",
    "    \n",
    "    return pd.DataFrame(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00b23a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def URL_to_table_csv(start_year,number_of_seasons):\n",
    "\n",
    "    for i in range(number_of_seasons):\n",
    "        # Creating a template of years for url\n",
    "        dummy_years = f\"{start_year+i}-{start_year+i+1}\"\n",
    "        base_dummy_url = f\"https://fbref.com/en/comps/9/{str(dummy_years)}/{str(dummy_years)}-Premier-League-Stats\"\n",
    "        print(base_dummy_url)\n",
    "\n",
    "        # Getting tags\n",
    "        soup = request_to_soup(url= base_dummy_url)\n",
    "\n",
    "        # Calling the scraper function\n",
    "        Squad_stats = scraper(soup_= soup)\n",
    "\n",
    "        # Creating a template for naming the files \n",
    "        file_name =f\"Premier_league_season_table_{dummy_years}\"\n",
    "\n",
    "        # Converting the dataframe to csv file\n",
    "        Season_table.to_csv(file_name)\n",
    "        if i == 0: \n",
    "            print(f\"{i+1} season successfully scraped ✔ \")\n",
    "        elif i >0:\n",
    "            print(f\"{i+1} seasons successfully scraped ✔ \")\n",
    "        if i == number_of_seasons-1:\n",
    "            print(f'All seasons scraped')\n",
    "        \n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f1c36bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://fbref.com/en/comps/9/2015-2016/2015-2016-Premier-League-Stats\n",
      "200\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "final_table() got an unexpected keyword argument 'headers_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4560/2763234511.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mURL_to_table_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_year\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2015\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumber_of_seasons\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4560/1352496547.py\u001b[0m in \u001b[0;36mURL_to_table_csv\u001b[1;34m(start_year, number_of_seasons)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# Calling the scraper function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mSquad_stats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscraper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup_\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Creating a template for naming the files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4560/1682201469.py\u001b[0m in \u001b[0;36mscraper\u001b[1;34m(soup_)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# Creating a final table in the as dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheaders_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtable_header_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtable_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtable_details\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: final_table() got an unexpected keyword argument 'headers_list'"
     ]
    }
   ],
   "source": [
    "URL_to_table_csv(start_year=2015,number_of_seasons=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bb4583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_years = 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1213dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://fbref.com/en/comps/9/2015/2015-Premier-League-Stats\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "base_dummy_url = f\"https://fbref.com/en/comps/9/{str(dummy_years)}/{str(dummy_years)}-Premier-League-Stats\"\n",
    "print(base_dummy_url)\n",
    "\n",
    "        # Getting tags\n",
    "soup_ = request_to_soup(url= base_dummy_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b69fa26a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table_tags' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4560/3695059181.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtable_header_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_extract_from_contents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable_tags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'table_tags' is not defined"
     ]
    }
   ],
   "source": [
    "table_header_list = text_extract_from_contents(table_tags.thead.tr.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c71a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_tags = soup_.find('table')\n",
    "    \n",
    "    # Table header section    \n",
    "    # Separating tags for scraping the text\n",
    "content_to_list(table_tags.thead.tr.contents)\n",
    "\n",
    "    # Scraping the text from tags contents\n",
    "table_header_list = text_extract_from_contents(table_tags.thead.tr.contents)\n",
    "    \n",
    "    # Table body section \n",
    "    # Scraping the body tags from table    \n",
    "table_details = content_to_list(table_tags.tbody.contents)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ff7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
